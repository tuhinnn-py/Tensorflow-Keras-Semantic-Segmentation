{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\ndef create_data_dict(inp_size=None):\n    X,y=list(),list()\n    feature_path='nn'\n    label_path='SegmentationClass'\n    path='/kaggle/input/pascalvoc/VOC2012'\n    \n    for file in os.listdir(os.path.join(path,label_path)):\n        X.append(img_to_array(load_img(os.path.join(path,feature_path,file[:-4]+'.jpg'),target_size=inp_size)))\n        y.append(img_to_array(load_img(os.path.join(path,label_path,file),target_size=inp_size)))\n        \n    return tf.convert_to_tensor(X),y\n    \nX,y=create_data_dict((128,128,3))\nX=X/255\n'''\nwith open('/kaggle/input/X.npy', 'wb') as f:\n    np.save(f,X)\nwith open('/kaggle/input/y.npy', 'wb') as f:\n    np.save(f,y)\n'''\nVOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n                [0, 64, 128]]\nVOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n               'diningtable', 'dog', 'horse', 'motorbike', 'person',\n               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']\n\ndef build_colormap2label():\n    colormap2label=np.zeros(256**3)\n    for i,color in enumerate(VOC_COLORMAP):\n        idx=(color[0]*256+color[1])*256+color[2]\n        colormap2label[idx]=i\n    return colormap2label\n\ndef voc_label_indices(colormap,colormap2label):\n    colormap=np.asarray(colormap,dtype=np.int32)\n    idx=(colormap[:,:,0]*256+colormap[:,:,1])*256+colormap[:,:,2]\n    return colormap2label[idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colormap2label=build_colormap2label()\ny=tf.convert_to_tensor([voc_label_indices(label,colormap2label) for label in y])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Model,Sequential\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D,Conv2DTranspose,BatchNormalization,Activation,Add,Input,Dropout\nfrom tensorflow.keras import regularizers\ndef resnet_block(n_filters,ip_model):\n    \n    bi=tf.keras.initializers.Constant(value=0.01)\n    init=tf.keras.initializers.he_uniform()\n    reg=None #regularizers.l1_l2(l1=1e-4, l2=1e-3)\n    \n    d=Conv2D(n_filters,(3,3),padding='same',kernel_initializer=init,bias_initializer=bi,kernel_regularizer=reg)(ip_model)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    \n    d=Conv2D(n_filters,(3,3),padding='same',kernel_initializer=init,bias_initializer=bi,kernel_regularizer=reg)(d)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    \n    d=Add()([d,ip_model])\n    return d\n\ndef get_model(ip_shape,n_categories):\n    \n    bi=tf.keras.initializers.Constant(value=0.01)\n    init=tf.keras.initializers.he_uniform()\n    reg=None #regularizers.l1_l2(l1=1e-4, l2=1e-3)\n    \n    ip=Input(shape=ip_shape)\n    d=Conv2D(64,(3,3),strides=2,padding='same',kernel_initializer=init,bias_initializer=bi,kernel_regularizer=reg)(ip)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    #d=Dropout(0.4)(d)\n    \n    d=Conv2D(128,(3,3),strides=2,padding='same',kernel_initializer=init,bias_initializer=bi,kernel_regularizer=reg)(d)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    #d=Dropout(0.4)(d)\n    \n    d=Conv2D(128,(3,3),strides=2,padding='same',kernel_initializer=init,bias_initializer=bi,kernel_regularizer=reg)(d)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    #d=Dropout(0.4)(d)\n    \n    d=Conv2D(128,(3,3),strides=2,padding='same',kernel_initializer=init,bias_initializer=bi,kernel_regularizer=reg)(d)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    #d=Dropout(0.4)(d)\n    \n    for i in range(10):\n        d=resnet_block(128,d)\n    #d=Dropout(0.4)(d)\n    \n    d=Conv2DTranspose(128,(3,3),strides=2,padding='same',kernel_initializer=init,bias_initializer=bi,kernel_regularizer=reg)(d)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    #d=Dropout(0.4)(d)\n    \n    d=Conv2DTranspose(128,(3,3),strides=2,padding='same',kernel_initializer=init,bias_initializer=bi,kernel_regularizer=reg)(d)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    #d=Dropout(0.4)(d)\n    \n    d=Conv2DTranspose(64,(3,3),strides=2,padding='same',kernel_initializer=init,bias_initializer=bi,kernel_regularizer=reg)(d)\n    d=BatchNormalization()(d)\n    d=Activation('relu')(d)\n    #d=Dropout(0.4)(d)\n    \n    d=Conv2DTranspose(n_categories,(3,3),strides=2,padding='same',kernel_initializer=init,bias_initializer=bi,kernel_regularizer=reg)(d)\n    d=BatchNormalization()(d)\n    d=tf.keras.activations.softmax(d,axis=-1)\n    \n    seg=Model(ip,d)\n    return seg\ninp_shape,n_categories=(128,128,3),len(VOC_CLASSES)\nn_categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n'''\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)nn\n\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\nwith tpu_strategy.scope():\n'''\nlr_schedule=tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.1,decay_steps=10000,decay_rate=0.9)\noptimizer=Adam(learning_rate=lr_schedule)\nmodel=get_model(inp_shape,n_categories)\nsse=tf.keras.losses.SparseCategoricalCrossentropy()\nmodel.compile(optimizer=Adam(lr=0.001),loss=sse,metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"tpu_strategy.num_replicas_in_sync","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X,y,validation_split=0.2,shuffle=True,epochs=1000,batch_size=128,verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('/kaggle/working/segnet.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img=np.asarray(tf.squeeze(model.predict(tf.expand_dims(X[279],axis=0))))\nimg=np.argmax(img,axis=-1)\nimage=np.zeros((128,128,3))\nfor i in range(128):\n    for j in range(128):\n        image[i][j]=np.asarray(VOC_COLORMAP[img[i][j]])\nplt.subplot(1,2,1)\nplt.imshow(X[279])\nplt.subplot(1,2,2)\nplt.imshow(image)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}